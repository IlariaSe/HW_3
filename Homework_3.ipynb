{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import enchant\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Airbnb_Texas_Rentals.csv')\n",
    "\n",
    "for i in range(df.index.max()+1):\n",
    "    file=open('test/doc_'+str(i+1)+\".tsv\",'w',newline='')\n",
    "    for j in range(9):\n",
    "        file.write('%s\\t'% df.iloc[i,j])\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df = pd.read_csv('Airbnb_Texas_Rentals.csv')\n",
    "df = df[df.drop('Unnamed: 0', axis= 1)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Read the file and create a single tsv file for each record .  \n",
    "with open('Airbnb_Texas_Rentals.csv') as csvin:\n",
    "    reader = csv.reader(csvin)\n",
    "    counter = 1\n",
    "    for row in reader:\n",
    "        with open(\"data/doc_\"+str(counter)+\".tsv\",'w') as tsvout:\n",
    "            writer = csv.writer(tsvout, delimiter='\\t')\n",
    "            writer.writerow(row)\n",
    "            counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the word. i.e. tokenize,stemming, and removing punctuations\n",
    "def wordNorm(text):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    Normalized = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_list = tokenizer.tokenize(text.lower())\n",
    "    Remove_stopwords = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    stem_words = [stemmer.stem(word) for word in Remove_stopwords]\n",
    "    \n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for word in stem_words:\n",
    "        if not word.isdigit() and len(word)>1 and d.check(word):#remove the punctuation\n",
    "            Normalized.append(word)\n",
    "    return Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readall_documents(path):\n",
    "    words = []\n",
    "    for file in glob.glob(path):\n",
    "        df = pd.read_table(file,sep='\\t',names=['average_rate_per_night','bedrooms_count',\n",
    "                                                'city','date_of_listing','description','latitude',\n",
    "                                                'longitude','title','url'])\n",
    "        desc = wordNorm(str(list(df['description'])))\n",
    "        title = wordNorm(str(list(df['title'])))\n",
    "        for des, tit in it.zip_longest(desc,title):\n",
    "            if(des is not None):\n",
    "                words.append(des)\n",
    "            if(tit is not None):\n",
    "                words.append(tit)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the files inside test folder. Test folder contains all the tsv files\n",
    "Allword = readall_documents('test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateVocabulary(allwords):\n",
    "    Vocabulary = {}\n",
    "    wordList = sorted(list(set(allwords)))\n",
    "    for ID, element in enumerate(wordList):\n",
    "        Vocabulary.update({element : ID})\n",
    "    return Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = CreateVocabulary(Allword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_freq(term, text):\n",
    "    count = 0\n",
    "    if len(text) <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for ter in text:\n",
    "            if ter == term:\n",
    "                count += 1\n",
    "        return count / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build invertedIndex\n",
    "def invertedIndex(vocabulary,path):\n",
    "    # invertedIndex = {termID : (doc, TF)}\n",
    "    invertedIndex = {}\n",
    "    counter = 0\n",
    "    for file in glob.glob(path):\n",
    "        df = pd.read_table(file,sep='\\t',names=['index','average_rate_per_night','bedrooms_count',\n",
    "                                                'city','date_of_listing','description','latitude',\n",
    "                                                'longitude','title','url'])\n",
    "        \n",
    "        desc = wordNorm(str(list(df['description'])))\n",
    "        title = wordNorm(str(list(df['title'])))\n",
    "        for word in vocabulary:\n",
    "            tf = term_freq(word, desc+title)\n",
    "            if(tf>0):\n",
    "                if(vocabulary[word] in invertedIndex.keys()):\n",
    "                    invertedIndex[vocabulary[word]].append(file)\n",
    "                else:\n",
    "                    invertedIndex[vocabulary[word]] = [file]\n",
    "\n",
    "    return invertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "invIndex = invertedIndex(voc,'test/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"lovely land\" #Accept the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnorm = wordNorm(query) #Normalize the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find a document that contains all the words in the qnorm\n",
    "inter = set()\n",
    "for word in qnorm:\n",
    "    if word in voc:\n",
    "        if(len(inter) >0):\n",
    "            inter = inter.intersection(set(invIndex[voc[word]]))\n",
    "        else:\n",
    "            inter = inter.union(invIndex[voc[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "=========:\n",
      "['Texas Starlight Ranch']\n",
      "\n",
      " Description\n",
      "=========:\n",
      "['Texas Starlight Ranch sits on 18 acres of land and is also a nature preserve. My place is close to restaurants and dining and family-friendly activities. Youâ€™ll love my place because of the ambiance and the outdoors space. My place is good for couples, solo adventurers, business travelers, families (with kids), and big groups. Texas Starlight Ranch is also great for Holiday Parties for Thanksgiving, Christmas and New Years.']\n",
      "\n",
      " City\n",
      "=========:\n",
      "['McKinney']\n",
      "\n",
      " URL\n",
      "=========:\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "for file in inter:\n",
    "    df = pd.read_table(file,sep='\\t',names=['index','average_rate_per_night','bedrooms_count',\n",
    "                                                'city','date_of_listing','description','latitude',\n",
    "                                                'longitude','title','url'])\n",
    "    print(\"Title\\n=========:\")\n",
    "    print(list(df['title']))\n",
    "    print(\"\\n Description\\n=========:\")\n",
    "    print(list(df['description']))\n",
    "    print(\"\\n City\\n=========:\")\n",
    "    print(list(df['city']))\n",
    "    print(\"\\n URL\\n=========:\")\n",
    "    print(list(df['url']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
